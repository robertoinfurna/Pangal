
import numpy as np
import astropy
from astropy.io import fits
from bisect import bisect_left
from scipy.special import erf
from scipy.interpolate import RegularGridInterpolator, interp1d
import itertools
import os

from dynesty import NestedSampler

import sys, os
sys.path.append(os.path.expanduser('~/Desktop/Pangal'))

from .image import Image
from .spectrum import Spectrum
from .filter import Filter, map_filter_names, nice_filter_names, default_plot_scale_lims, default_plot_units, default_cmaps



# UTILS
# Base directory containing the “DISKEVOL.RES_L0.05_V*” files
this_dir = os.path.dirname(os.path.abspath(__file__))

# Construct full path to the data directory
data_dir = os.path.join(this_dir, ".", "data")
data_dir = os.path.normpath(data_dir)



def load_spectrum_models_from_fits(filename):
    with fits.open(filename) as hdul:
        # Wavelength array from primary HDU
        wl,resolution = hdul[0].data
        nmodels = len(hdul) - 1

        models = []
        for i in range(1, len(hdul)):
            data = hdul[i].data
            header = hdul[i].header


            spec = Spectrum(wl=wl,resolution=resolution,) #flux=data["FLUX"])

            spec.flux_young = data["FLUX_YOUNG"]
            spec.flux_old   = data["FLUX_OLD"]
            
            # Keep the model's metadata
            spec.header.update(header)

            models.append(spec)

    return models


def load_nebular_tables(self,wl,resolution,emimetal,emimodel):
    """
    Load and process precomputed nebular emission line tables from Byler et al. models.

    This function reads tabulated emission line luminosities (in erg/s per ionizing photon)
    for a given metallicity and emission model (2017 or 2018), and convolves the lines with
    the desired spectral resolution and wavelength grid. The resulting emission line spectra 
    are suitable for adding to stellar SEDs generated by codes like CIGALE.

    The lines are modeled as Gaussians, and the convolution simulates how they would appear
    in an observed spectrum, taking into account the resolution and pixel binning. An 
    interpolation function is returned, allowing the user to compute the full nebular 
    emission spectrum for any given ionization parameter and stellar population age.

    Parameters:
        wl (ndarray): Wavelength array in Angstroms.
        resolution (ndarray): Spectral resolution (R = λ/Δλ) array matching `wl`.
        emimetal (float): Metallicity of the model to load (closest available will be used).
        emimodel (str): Emission line model version ('2017' or '2018').

    Returns:
        nebular_emission_spectrum (function): Callable(ion, age) → emission spectrum on wl grid.
        emm_ions (ndarray): Ionization parameter grid points used in the model.
        emm_ages (ndarray): Age grid points (in Myr) used in the model.
    """
    
    wl_lyman = 912.
    ilyman = np.searchsorted(wl, wl_lyman, side='left') #wavelength just above Lyman limit
    lycont_wls = np.r_[wl[:ilyman], np.array([wl_lyman])]
    clyman_young = None #A list of two elements, first is for phot, the other for spec
    clyman_old   = None #A list of two elements, first is for phot, the other for spec

    # Emission line wavelengths have to be in VACUUM
    
    if emimodel == '2018':
        byler_bins = [382,9,7]
        byler_fname = 'nebular_Byler_mist_2018.lines'
        metallist = np.array([6.3245e-05,2.0000e-04,3.5565e-04,6.3245e-04,1.1246e-03,2.0000e-03,3.5565e-03,6.3245e-03,1.1246e-02,2.000e-02,3.5565e-02,6.3245e-02])
        metalstrg = np.array(['-2.5000e+00','-2.0000e+00','-1.7500e+00','-1.5000e+00','-1.2500e+00','-1.0000e+00','-7.5000e-01','-5.0000e-01','-2.5000e-01','0.0000e+00','2.5000e-01','5.0000e-01'])
    else:
        byler_bins = [128,10,7]
        byler_fname = 'nebular_Byler_mist_2017.lines'
        metallist = np.array([0.00020,0.00063246,0.00209426,0.00526054,0.00814761,0.01002374,0.01261915,0.01588656,0.02,0.02517851,0.03169786])
        metalstrg = np.array(['-1.9800e+00','-1.5000e+00','-9.8000e-01','-5.8000e-01','-3.9000e-01','-3.0000e-01','-2.0000e-01','-1.0000e-01','0.0000e+00','1.0000e-01','2.0000e-01'])
    
    print("Loading nebular lines templates from ",byler_fname)

    emm_scales = np.zeros((byler_bins[2],byler_bins[1],byler_bins[0]), dtype=float)
    emm_wls    = np.zeros(byler_bins[0],        dtype=float)
    emm_ages   = np.zeros(byler_bins[1],        dtype=float)
    emm_ions   = np.zeros(byler_bins[2],        dtype=float)
    icnt = 0
    rline = 0
    iline = 0
    
    
    metind = np.argmin(np.abs(metallist-emimetal))  # Select the closest metallicity available
    print(' Emission line metallicity requested {}, found {:5.4f}'.format(emimetal,metallist[metind]))
    emimetal = metallist[metind]


    # load emission lines tables
    file_path = os.path.join(data_dir, byler_fname)

    with open(file_path, 'r') as file:
        
        for line in file:
            if line[0] != '#':
                temp = (line.strip()).split(None)
                if not iline: #Read wave line
                    emm_wls[:] = np.array(temp, dtype=float)
                    iline = 1
                else:
                    if rline: #Read line fluxes
                        emm_scales[icnt%7,icnt//7,:] = np.array(temp, dtype=float)*3.839e33 #erg/s #output should be in erg/s/QHO
                        icnt += 1
                    if len(temp) == 3 and temp[0] == metalstrg[metind]:
                        rline = 1
                        emm_ages[icnt//7] = float(temp[1])/1e6
                        emm_ions[icnt%7]  = float(temp[2])
                    else:
                        rline = 0


    print(f"Tabulated values for ionized gas age (Myr): {emm_ages}")
    print(f"Tabulated values for ionization coefficient: {emm_ions}")

    # Filters out non-physical or extremely high wavelengths ?? Why ??
    keep_scale = (emm_wls<1E5)        
    emm_scales = emm_scales[:,:,keep_scale]
    emm_wls    = emm_wls[keep_scale]

    # Convolve lines to model resolution
    # Emission lines are modeled as Gaussians centered at their rest wavelengths.
    # To add these lines realistically, you integrate the Gaussian emission line profile over each pixel's wavelength bin.
    # Simulates how nebular emission lines would appear in a spectrum observed at a given resolution and wavelength sampling
    
    dpix = np.diff(wl)
    wl_edges  = np.r_[np.array([wl[0]-dpix[0]/2.]), np.r_[wl[1:]-dpix/2., np.array([wl[-1]+dpix[-1]/2.])]]
    delta_lambda = wl/resolution
    res_lines = np.interp(emm_wls, wl,delta_lambda)/2.355
    

    emm_lines_all = np.zeros((len(emm_ions), len(emm_ages), len(wl)), dtype=float)

    for jj in range(len(emm_ions)):
        for ii in range(len(emm_ages)):
            this_scale = emm_scales[jj,ii,:]
            emm_lines_all[jj,ii,:] = np.sum(this_scale[:,None]*\
                np.diff(0.5*(1.+erf((wl_edges[None,:]-emm_wls[:,None])/\
                np.sqrt(2.*res_lines**2)[:,None])), axis=1)/np.diff(wl_edges), axis=0)


    # Create interpolator: maps (ion, age) -> spectrum on wl grid
    interp_func = RegularGridInterpolator(
        points=(emm_ions, emm_ages),  # shape (n_ions, n_ages)
        values=emm_lines_all,         # shape (n_ions, n_ages, n_wl)
        bounds_error=False,
        fill_value=0.0
    )

    # Define a function for convenience
    def nebular_emission_spectrum(ion, age):
        input_point = np.array([[ion, age]])  # shape (1, 2)
        return interp_func(input_point)[0]    # returns (n_wl,)
    
    print("Loading of nebular lines templates completed.")
    
    return nebular_emission_spectrum, emm_ions, emm_ages



def load_dust_emission_models(self, wl, dustemimodel):
    """
    Loads dust emission templates from Dale & Helou 2002 (dustemimodel = 'dh02') and return a function of alpha
    or Draine & Li 2014 (dustemimodel = 'dl14'), interpolated on the input wavelength grid.
    """

    alpha_file = os.path.join(data_dir, f'alpha_{dustemimodel}.dat')
    spectra_file = os.path.join(data_dir, f'spectra_{dustemimodel}.dat')

    # Check files exist
    if not os.path.exists(alpha_file):
        raise FileNotFoundError(f"Missing file: {alpha_file}")
    if not os.path.exists(spectra_file):
        raise FileNotFoundError(f"Missing file: {spectra_file}")

    #print(f"Loading dust emission templates from: {alpha_file}")

    # Load alpha values and spectra
    dustem_alpha = np.loadtxt(alpha_file, usecols=(0,))
    dustem_wl = np.loadtxt(spectra_file, usecols=(0,)) * 1e4  # assuming microns to Angstroms
    full_spectra = np.loadtxt(spectra_file)

    # Initialize template matrix
    tdustem = np.zeros((len(dustem_alpha), len(wl)), dtype=float)

    for ii in range(len(dustem_alpha)):
        tdust = 10 ** full_spectra[:, ii + 1]  # column 1 is wavelength, so ii+1
        tdustem[ii, :] = np.interp(wl, dustem_wl, tdust, left=0.0, right=0.0) / wl

    # Normalize each template to Lbol = 1
    norm = np.trapz(tdustem, wl, axis=1)
    tdustem /= norm[:, None]

    dustem_func = interp1d(dustem_alpha, tdustem, axis=0, bounds_error=True)

    # Define a function for convenience
    def dust_emission_spectrum(alpha):
        return dustem_func(alpha)

    print(f"Tabulated alpha values from 'alpha_{dustemimodel}.dat': {dustem_alpha}")
    print("Loading of dust emission templates completed.")

    return dust_emission_spectrum, dustem_alpha




def model_grid_interpolator(self, model_list, param_names):
    """
    Build N-dimensional interpolators for young and old fluxes on the model grid,
    and return callables that output spectra resampled onto self.model_wl.
    """

    # Native (short) wavelength grid from SPS models
    short_wl = np.array(model_list[0].wl, dtype=float)

    # --- Step 1: Build param space ---
    param_tuples = []
    param_to_model = {}
    for model in model_list:
        try:
            values = tuple(float(model.header[k]) for k in param_names)
        except KeyError as e:
            raise KeyError(f"Model is missing parameter {e} in header.")
        param_tuples.append(values)
        param_to_model[values] = model

    # --- Step 2: Build grid axes ---
    grid_axes = [np.array(sorted(set(p[i] for p in param_tuples)), dtype=float)
                 for i in range(len(param_names))]

    # --- Step 3: Allocate grids ---
    grid_shape = tuple(len(ax) for ax in grid_axes)
    n_wl = np.asarray(model_list[0].flux_young).size

    flux_young_grid = np.zeros(grid_shape + (n_wl,), dtype=float)
    flux_old_grid   = np.zeros(grid_shape + (n_wl,), dtype=float)

    # --- Step 4: Fill the grids (store flux per unit mass, like mcspf) ---
    for idxs in np.ndindex(*grid_shape):
        key = tuple(grid_axes[i][idxs[i]] for i in range(len(grid_axes)))
        model = param_to_model[key]
        mstar = float(model.header["MSTAR"])  # you said: linear in FITS
        flux_young_grid[idxs] = np.asarray(model.flux_young, dtype=float) / mstar
        flux_old_grid[idxs]   = np.asarray(model.flux_old,   dtype=float) / mstar

    # --- Step 5: Build interpolators on the native wavelength grid ---
    interp_young = RegularGridInterpolator(
        points=grid_axes, values=flux_young_grid,
        bounds_error=True, fill_value=None
    )
    interp_old = RegularGridInterpolator(
        points=grid_axes, values=flux_old_grid,
        bounds_error=True, fill_value=None
    )

    # --- Wrappers: interpolate in parameter space, then resample in wavelength to self.model_wl ---
    def _check_bounds(x):
        for i, val in enumerate(x):
            if val < grid_axes[i][0] or val > grid_axes[i][-1]:
                raise ValueError(
                    f"Parameter '{param_names[i]}'={val} is outside grid range "
                    f"[{grid_axes[i][0]}, {grid_axes[i][-1]}]"
                )

    def interp_flux_young(**kwargs):
        x = [float(kwargs[name]) for name in param_names]
        _check_bounds(x)

        # RGI wants (n_points, ndim)
        spec_short = interp_young(np.array([x], dtype=float))[0]  # (n_wl,)

        # Resample to the extended wavelength grid, matching mcspf left/right=0 behavior
        return np.interp(self.model_wl, short_wl, spec_short, left=0.0, right=0.0)

    def interp_flux_old(**kwargs):
        x = [float(kwargs[name]) for name in param_names]
        _check_bounds(x)

        spec_short = interp_old(np.array([x], dtype=float))[0]
        return np.interp(self.model_wl, short_wl, spec_short, left=0.0, right=0.0)

    return interp_flux_young, interp_flux_old, grid_axes, short_wl



"""

def model_grid_interpolator(self, model_list, param_names,):

    n_wl = len(model_list[0].wl)

    #Generate output grid and define interpolation routine to be used
    if len(param_names)==1:
        young_grid = np.zeros((len(self.model_pars_arr[0]), n_wl), dtype=float)
        old_grid = np.zeros((len(self.model_pars_arr[0]), n_wl), dtype=float)
        age_grid = np.zeros((len(self.model_pars_arr[0]), 2),         dtype=float)
        interp = _interp
    elif len(param_names)==2:
        young_grid = np.zeros((len(self.model_pars_arr[0]),len(self.model_pars_arr[1]), n_wl), dtype=float)
        old_grid = np.zeros((len(self.model_pars_arr[0]), n_wl), dtype=float)
        age_grid = np.zeros((len(self.model_pars_arr[0]),len(self.model_pars_arr[1]), 2),         dtype=float)
        interp = _bi_interp
    #elif len(param_names)==3:
    #    self.mod_grid = np.zeros((self.par_len[0], self.par_len[1], self.par_len[2], self.n_wl), dtype=float)
    #    self.age_grid = np.zeros((self.par_len[0], self.par_len[1], self.par_len[2], 2),         dtype=float)
    #    self.phy_grid = np.zeros((self.par_len[0], self.par_len[1], self.par_len[2], 2),         dtype=float)
    #    interp = _tri_interp
    else:
        print('ERROR: We cannot handle SFH grids with more than 3 dimensions. Abort')
        exit()
    
    #Grid where the fractional flux from young populations is stored
    #self.fym_grid = np.zeros_like(self.mod_grid)


    for i, model in enumerate(model_list):            
        
        mmass  = model.header['MSTAR']
        mmetal = model.header['METAL']
        
        #This should be cleaned up
        #if sfh_age_par == -1:
        #   mage = mfile[ii].header['AGE']
        #elif sfh_age_par >=0 and sfh_age_par<=10:
        #   mage = mfile[ii].header[sfh_pars[sfh_age_par]]
        #else:
        #   mage = sfh_age_par      
        
        pos_tuple = []
        for j,param in enumerate(param_names):
            tmppar = model.header[param]
            pos_tuple.append(np.where(tmppar == self.model_pars_arr[0])[0])
        
        pos_tuple.append(Ellipsis)
        pos_tuple = tuple(pos_tuple)
            
        #self.mod_grid[pos_tuple] = np.interp(self.wl, twl, mdata[:, 0]/mmass, left=0, right=0)
        #self.fym_grid[pos_tuple] = np.interp(self.wl, twl, mdata[:, 1], left=0, right=0)
        #self.age_grid[pos_tuple] = mage
        #self.phy_grid[pos_tuple] = mmass 

    
    self.age_max = int(np.nanmax(self.age_grid))
    self.sfh_array = np.ones((self.age_max), dtype=float)
    if self.sfh_npars==1:
        self.sfh_grid = np.zeros((self.par_len[0], self.age_max), dtype=float)
    elif self.sfh_npars==2:
        self.sfh_grid = np.zeros((self.par_len[0], self.par_len[1], self.age_max), dtype=float)
    elif self.sfh_npars==3:
        self.sfh_grid = np.zeros((self.par_len[0], self.par_len[1], self.par_len[2], self.age_max), dtype=float)
        



        
        #Grid where the fractional flux from young populations is stored
        #self.fym_grid = np.zeros_like(self.mod_grid)
    











def _tri_interp(data_cube, valuetpl, arraytpl):
    #locate vertices
    ilo = bisect_left(arraytpl[0], valuetpl[0])-1
    jlo = bisect_left(arraytpl[1], valuetpl[1])-1
    klo = bisect_left(arraytpl[2], valuetpl[2])-1
    
    di = (valuetpl[0] - arraytpl[0][ilo])/(arraytpl[0][ilo+1]-arraytpl[0][ilo])
    dj = (valuetpl[1] - arraytpl[1][jlo])/(arraytpl[1][jlo+1]-arraytpl[1][jlo])
    dk = (valuetpl[2] - arraytpl[2][klo])/(arraytpl[2][klo+1]-arraytpl[2][klo])

    interp_out = data_cube[ilo,jlo,klo,:]       * (1.-di)*(1.-dj)*(1.-dk) + \
                 data_cube[ilo,jlo,klo+1,:]     * (1.-di)*(1.-dj)*dk + \
                 data_cube[ilo,jlo+1,klo,:]     * (1.-di)*dj*(1.-dk) + \
                 data_cube[ilo,jlo+1,klo+1,:]   * (1.-di)*dj*dk + \
                 data_cube[ilo+1,jlo,klo,:]     * di*(1.-dj)*(1.-dk) + \
                 data_cube[ilo+1,jlo,klo+1,:]   * di*(1.-dj)*dk + \
                 data_cube[ilo+1,jlo+1,klo,:]   * di*dj*(1.-dk) + \
                 data_cube[ilo+1,jlo+1,klo+1,:] * di*dj*dk

    return interp_out

def _bi_interp(data_cube, valuetpl, arraytpl):
    #locate vertices
    ilo = bisect_left(arraytpl[0], valuetpl[0])-1
    jlo = bisect_left(arraytpl[1], valuetpl[1])-1
       
    di = (valuetpl[0] - arraytpl[0][ilo])/(arraytpl[0][ilo+1]-arraytpl[0][ilo])
    dj = (valuetpl[1] - arraytpl[1][jlo])/(arraytpl[1][jlo+1]-arraytpl[1][jlo])

    interp_out = data_cube[ilo,jlo,:]     * (1.-di)*(1.-dj) + \
                 data_cube[ilo,jlo+1,:]   * (1.-di)*dj + \
                 data_cube[ilo+1,jlo,:]   * di*(1.-dj) + \
                 data_cube[ilo+1,jlo+1,:] * di*dj

    return interp_out

def _interp(data_cube, valuetpl, arraytpl):
    #locate vertices
    ilo = bisect_left(arraytpl[0], valuetpl[0])-1
    
    di = (valuetpl[0] - arraytpl[0][ilo])/(arraytpl[0][ilo+1]-arraytpl[0][ilo])

    interp_out = data_cube[ilo,:]   * (1.-di) + \
                 data_cube[ilo+1,:] * di

    return interp_out

"""



    